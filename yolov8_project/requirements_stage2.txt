# Stage 2: Vision-Language Model Dependencies
# For conditional classification using VLMs

# Core ML libraries
torch>=2.0.0
transformers>=4.35.0
accelerate>=0.20.0
pillow>=9.0.0

# Model-specific dependencies
# Qwen2-VL
tiktoken>=0.5.0

# Utilities
psutil>=5.9.0
pyyaml>=6.0

# Optional: For quantization
# bitsandbytes>=0.41.0  # For INT8/INT4 quantization
# autoawq>=0.1.0  # For AWQ quantization

# Optional: For LoRA fine-tuning
# peft>=0.5.0  # Parameter-Efficient Fine-Tuning


